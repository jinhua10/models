# æˆ‘å°†åœ¨githubå•ç‹¬å¼„ä¸ªä»“åº“å­˜æ”¾ç¼–è¯‘åçš„onnxæ¨¡å‹ï¼Œæ–¹ä¾¿å¤§å®¶ç›´æ¥ä¸‹è½½ä½¿ç”¨ï¼Œå¦‚æœæ ¹æ®ä¸‹é¢çš„è„šæœ¬ä¸‹è½½æœ‰é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥å»githubä»“åº“ä¸‹è½½å¯¹åº”æ¨¡å‹
ä»“åº“åœ°å€ï¼š[]()

# ğŸš€ ä¸€é”®ä¸‹è½½è„šæœ¬ä½¿ç”¨æŒ‡å—

## ğŸ“… æœ€åæ›´æ–°
2025-12-05 01:30:00

## âœ¨ ç‰¹æ€§

ä¸¤ä¸ªè„šæœ¬éƒ½æ”¯æŒï¼š
- âœ… **é›¶ä¾èµ–è¿è¡Œ** - å…¨æ–° Python ç¯å¢ƒä¹Ÿèƒ½ç”¨
- âœ… **è‡ªåŠ¨å®‰è£…ä¾èµ–** - ç¼ºå¤±çš„åŒ…è‡ªåŠ¨å®‰è£…
- âœ… **è‡ªåŠ¨ ONNX è½¬æ¢** - ä¸‹è½½åç«‹å³å¯ç”¨
- âœ… **æ™ºèƒ½é”™è¯¯å¤„ç†** - æ¸…æ™°çš„æç¤ºå’Œå»ºè®®

---

## ğŸ“¦ è„šæœ¬ 1: download_qwen_onnx.py

### ç”¨é€”
ä¸‹è½½ Qwen PPL æ¨¡å‹å¹¶è½¬æ¢ä¸º ONNX æ ¼å¼ï¼ˆç”¨äº PPL æœåŠ¡ï¼‰

### ä½¿ç”¨æ–¹æ³•

```bash
# ä¸‹è½½ Qwen2.5-0.5Bï¼ˆè½»é‡çº§ï¼Œæ¨èï¼‰
python scripts/download_qwen_onnx.py --model 0.5b

# ä¸‹è½½ Qwen2.5-1.5Bï¼ˆå¹³è¡¡ï¼‰
python scripts/download_qwen_onnx.py --model 1.5b

# ä¸‹è½½ Qwen2-7Bï¼ˆé«˜è´¨é‡ï¼‰
python scripts/download_qwen_onnx.py --model 7b

# ä½¿ç”¨å›½å†…é•œåƒï¼ˆæ›´å¿«ï¼‰
python scripts/download_qwen_onnx.py --model 1.5b --mirror

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python scripts/download_qwen_onnx.py --model 1.5b --output ./my_models
```

### è‡ªåŠ¨å®‰è£…çš„ä¾èµ–

- `transformers>=4.30.0`
- `optimum[onnxruntime]>=1.14.0`
- `onnxruntime>=1.15.0`
- `torch>=2.0.0`
- `onnxscript>=0.1.0`

### è¾“å‡º

```
models/
â””â”€â”€ qwen2.5-1.5b-instruct/
    â”œâ”€â”€ model.onnx          (1.3 MB)   âœ…
    â”œâ”€â”€ model.onnx_data     (7.1 GB)   âœ…
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ config.json
```

---

## ğŸ“¦ è„šæœ¬ 2: download_embedding_model.py

### ç”¨é€”
ä¸‹è½½å›½äº§å‘é‡åµŒå…¥æ¨¡å‹å¹¶è½¬æ¢ä¸º ONNX æ ¼å¼ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰

### ä½¿ç”¨æ–¹æ³•

```bash
# ä¸‹è½½ BGE-M3ï¼ˆæœ€æ¨èï¼Œæ™ºæºç ”ç©¶é™¢ï¼‰
python scripts/download_embedding_model.py --model bge-m3

# ä¸‹è½½ BGE-Base-ZHï¼ˆè½»é‡çº§ï¼‰
python scripts/download_embedding_model.py --model bge-base-zh

# ä¸‹è½½ BGE-Large-ZHï¼ˆé«˜è´¨é‡ï¼‰
python scripts/download_embedding_model.py --model bge-large-zh

# ä½¿ç”¨é­”æ­ç¤¾åŒºé•œåƒï¼ˆå›½å†…å¿«ï¼‰
python scripts/download_embedding_model.py --model bge-m3 --mirror

# åªä¸‹è½½ä¸è½¬æ¢ ONNX
python scripts/download_embedding_model.py --model bge-m3 --no-convert-onnx

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python scripts/download_embedding_model.py --model bge-m3 --output ./my_models
```

### è‡ªåŠ¨å®‰è£…çš„ä¾èµ–

**åŸºç¡€ä¾èµ–**ï¼š
- `sentence-transformers>=2.0.0`
- `torch>=2.0.0`
- `transformers>=4.30.0`
- `optimum[onnxruntime]>=1.14.0`
- `onnxruntime>=1.15.0`
- `onnxscript>=0.1.0`

**ä½¿ç”¨ --mirror æ—¶é¢å¤–å®‰è£…**ï¼š
- `modelscope>=1.0.0`

### è¾“å‡º

```
models/
â””â”€â”€ bge-m3/
    â”œâ”€â”€ model.onnx          (0.5 MB)   âœ…
    â”œâ”€â”€ model.onnx_data     (2.16 GB)  âœ…
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ config.json
```

**æ³¨æ„**ï¼š
- âœ… è½¬æ¢è¿‡ç¨‹ä¸­ä¼šåˆ›å»ºä¸´æ—¶ç›®å½•ï¼ˆå¦‚ `bge-m3-onnx`ï¼‰
- âœ… ä¸´æ—¶ç›®å½•åœ¨è½¬æ¢å®Œæˆåä¼š**è‡ªåŠ¨æ¸…ç†**ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤
- âœ… æœ€ç»ˆåªä¿ç•™åŸå§‹æ¨¡å‹ç›®å½•åŠå…¶ä¸­çš„ ONNX æ–‡ä»¶

---

## ğŸ¯ å®Œæ•´ä½¿ç”¨æµç¨‹

### æ­¥éª¤ 1ï¼šä¸‹è½½æ¨¡å‹

```bash
# 1. ä¸‹è½½ PPL æ¨¡å‹
python scripts/download_qwen_onnx.py --model 1.5b --mirror

# 2. ä¸‹è½½å‘é‡æ£€ç´¢æ¨¡å‹
python scripts/download_embedding_model.py --model bge-m3 --mirror
```

### æ­¥éª¤ 2ï¼šé…ç½®åº”ç”¨

æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `./models/` ç›®å½•ï¼Œé…ç½®å·²ç»é¢„è®¾å¥½ï¼š

```yaml
# application.ymlï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
knowledge:
  qa:
    ppl:
      ollama:
        model: qwen2.5:1.5b
      onnx:
        model-path: ./models/qwen2.5-1.5b-instruct/model.onnx
    
    vector-search:
      model:
        name: bge-m3
        path: ./models/bge-m3/model.onnx
```

### æ­¥éª¤ 3ï¼šå¯åŠ¨åº”ç”¨

```bash
./mvnw spring-boot:run
```

### æ­¥éª¤ 4ï¼šé‡å»ºç´¢å¼•

```bash
# è®¿é—® http://localhost:8080
# ç‚¹å‡» "æ–‡æ¡£ç®¡ç†" â†’ "é‡å»ºç´¢å¼•"
```

---

## ğŸ’¡ å¸¸è§åœºæ™¯

### åœºæ™¯ 1ï¼šé¦–æ¬¡å®‰è£…

```bash
# å…¨æ–° Python ç¯å¢ƒï¼Œä»€ä¹ˆéƒ½æ²¡è£…
python scripts/download_qwen_onnx.py --model 1.5b

# âœ… è„šæœ¬ä¼šè‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–
# âœ… ä¸‹è½½å¹¶è½¬æ¢æ¨¡å‹
# âœ… éªŒè¯æ¨¡å‹å¯ç”¨
```

### åœºæ™¯ 2ï¼šç½‘ç»œæ…¢

```bash
# ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ
python scripts/download_qwen_onnx.py --model 1.5b --mirror
python scripts/download_embedding_model.py --model bge-m3 --mirror
```

### åœºæ™¯ 3ï¼šç£ç›˜ç©ºé—´æœ‰é™

```bash
# ä½¿ç”¨å°æ¨¡å‹
python scripts/download_qwen_onnx.py --model 0.5b
python scripts/download_embedding_model.py --model bge-base-zh
```

### åœºæ™¯ 4ï¼šåªéœ€è¦ PyTorch ç‰ˆæœ¬

```bash
# ä¸è½¬æ¢ ONNX
python scripts/download_embedding_model.py --model bge-m3 --no-convert-onnx
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šä¾èµ–å®‰è£…å¤±è´¥

**ç°è±¡**ï¼š
```
âŒ ä»¥ä¸‹ä¾èµ–å®‰è£…å¤±è´¥: torch
```

**è§£å†³**ï¼š
```bash
# æ‰‹åŠ¨å®‰è£…å¤±è´¥çš„ä¾èµ–
pip install torch>=2.0.0

# ç„¶åé‡æ–°è¿è¡Œè„šæœ¬
python scripts/download_qwen_onnx.py --model 1.5b
```

### é—®é¢˜ 2ï¼šç½‘ç»œè¶…æ—¶

**è§£å†³**ï¼š
```bash
# 1. ä½¿ç”¨é•œåƒ
python scripts/download_qwen_onnx.py --model 1.5b --mirror

# 2. æˆ–é…ç½® pip é•œåƒ
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### é—®é¢˜ 3ï¼šç£ç›˜ç©ºé—´ä¸è¶³

**æ£€æŸ¥**ï¼š
```bash
# æŸ¥çœ‹å¯ç”¨ç©ºé—´
df -h  # Linux/Mac
wmic logicaldisk get size,freespace,caption  # Windows
```

**è§£å†³**ï¼š
- Qwen2.5-0.5B: éœ€è¦ ~1 GB
- Qwen2.5-1.5B: éœ€è¦ ~7 GB
- Qwen2-7B: éœ€è¦ ~15 GB
- BGE-M3: éœ€è¦ ~2.5 GB
- BGE-Base-ZH: éœ€è¦ ~500 MB

---

## âœ… éªŒè¯å®‰è£…

### éªŒè¯è„šæœ¬å¯ç”¨

```bash
# æŸ¥çœ‹å¸®åŠ©
python scripts/download_qwen_onnx.py --help
python scripts/download_embedding_model.py --help
```

### éªŒè¯æ¨¡å‹å·²ä¸‹è½½

```bash
# æ£€æŸ¥ Qwen æ¨¡å‹
ls models/qwen2.5-1.5b-instruct/

# æ£€æŸ¥ BGE æ¨¡å‹
ls models/bge-m3/

# éªŒè¯ ONNX æ–‡ä»¶
ls models/*/model.onnx
ls models/*/model.onnx_data
```

---

## ğŸ“š æ¨èç»„åˆ

### å¼€å‘ç¯å¢ƒï¼ˆè½»é‡çº§ï¼‰

```bash
python scripts/download_qwen_onnx.py --model 0.5b
python scripts/download_embedding_model.py --model bge-base-zh
# æ€»å¤§å°: ~1.5 GB
```

### ç”Ÿäº§ç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
python scripts/download_qwen_onnx.py --model 1.5b --mirror
python scripts/download_embedding_model.py --model bge-m3 --mirror
# æ€»å¤§å°: ~9.5 GB
```

### é«˜æ€§èƒ½ç¯å¢ƒ

```bash
python scripts/download_qwen_onnx.py --model 7b
python scripts/download_embedding_model.py --model bge-large-zh
# æ€»å¤§å°: ~16 GB
```

---

## ğŸ‰ æ€»ç»“

### æ”¹è¿›æˆæœ

1. âœ… **å®Œå…¨è‡ªåŠ¨åŒ–** - ä¸€æ¡å‘½ä»¤æå®š
2. âœ… **é›¶é…ç½®** - æ— éœ€æ‰‹åŠ¨å®‰è£…ä¾èµ–
3. âœ… **å…¨æ–°ç¯å¢ƒæ”¯æŒ** - Python åˆšè£…ä¹Ÿèƒ½ç”¨
4. âœ… **æ™ºèƒ½é”™è¯¯å¤„ç†** - æ¸…æ™°çš„æç¤º
5. âœ… **è‡ªåŠ¨ ONNX è½¬æ¢** - ç«‹å³å¯ç”¨

### ä½¿ç”¨ä½“éªŒ

**ä¹‹å‰**ï¼š
```bash
pip install transformers optimum onnxruntime torch onnxscript
python scripts/download_qwen_onnx.py --model 1.5b
# å¯èƒ½è¿˜éœ€è¦æ‰‹åŠ¨è½¬æ¢...
```

**ç°åœ¨**ï¼š
```bash
python scripts/download_qwen_onnx.py --model 1.5b
# å®Œæˆï¼âœ¨
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-12-05 01:30:00  
**çŠ¶æ€**: âœ… **å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œå¼€ç®±å³ç”¨ï¼**

